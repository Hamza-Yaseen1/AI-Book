# Data Model: Voice Commands with OpenAI Whisper and LLM Cognitive Planning

## VoiceCommand
- **command_id**: Unique identifier for each recognized voice command
- **audio_data**: Raw audio input (or reference to stored audio)
- **transcribed_text**: Text from Whisper speech-to-text conversion
- **confidence_score**: Confidence level of speech recognition (0.0-1.0)
- **intent**: Parsed intent from the command (e.g., "move_forward", "pick_object")
- **timestamp**: When the command was received
- **context**: Environmental context at time of command
- **status**: Enum (pending, processed, failed, rejected) for command processing state

## CognitivePlan
- **plan_id**: Unique identifier for each cognitive plan
- **goal_description**: High-level goal provided to the LLM (e.g., "bring me water")
- **generated_steps**: Ordered list of actions generated by the LLM
- **estimated_duration**: Predicted time to complete the plan
- **confidence_level**: LLM's confidence in the plan's success (0.0-1.0)
- **constraints**: Safety and environmental constraints for the plan
- **status**: Enum (planning, approved, executing, completed, failed)
- **created_timestamp**: When the plan was generated
- **executed_by**: Reference to the robot that executed the plan

## ActionStep
- **step_id**: Unique identifier for each action step
- **plan_id**: Reference to the parent cognitive plan
- **action_type**: Enum (navigation, manipulation, communication, sensing, wait)
- **parameters**: Dictionary of action-specific parameters (coordinates, object IDs, etc.)
- **prerequisites**: Conditions that must be met before executing this step
- **expected_outcome**: Expected result of the action
- **timeout**: Maximum time to complete the action
- **success_criteria**: How to determine if the action was successful

## RobotState
- **state_id**: Unique identifier for each state snapshot
- **timestamp**: When the state was recorded
- **position**: Current 3D position and orientation of the robot
- **joint_angles**: Current positions of all robot joints
- **sensor_data**: Current readings from all sensors
- **battery_level**: Current battery percentage
- **active_commands**: List of currently executing commands
- **safety_status**: Enum (normal, warning, emergency_stop, degraded)

## SafetyLog
- **log_id**: Unique identifier for each safety event
- **timestamp**: When the safety event occurred
- **event_type**: Enum (command_rejected, emergency_stop, constraint_violation, safety_check_passed)
- **triggering_action**: What action triggered the safety event
- **safety_check**: Which safety check was performed
- **result**: Outcome of the safety check
- **mitigation_action**: Action taken to address the safety event
- **user_notification**: Whether the user was notified of the event

## StudentProject
- **project_id**: Unique identifier for each student project instance
- **student_id**: Reference to the student or team
- **project_phase**: Enum (setup, voice_integration, llm_planning, integration, final_demo)
- **progress_tracking**: List of completed milestones
- **code_submissions**: References to student code submissions
- **evaluation_scores**: Scores for different aspects of the project
- **feedback_history**: Instructor feedback and comments
- **completed_timestamp**: When the project was completed

## LLMInteraction
- **interaction_id**: Unique identifier for each LLM query/response pair
- **query**: The input sent to the LLM
- **response**: The LLM's response
- **model_used**: Which LLM was used (e.g., "gpt-4", "llama-2")
- **tokens_used**: Number of tokens in the query and response
- **processing_time**: Time taken for the LLM to respond
- **context**: Environmental context provided to the LLM
- **validation_result**: Whether the response was valid for the intended use